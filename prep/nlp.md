NLP and spaCy
=======================

spaCy is an open-source NLP library for Python designed for quick experimentation and applied NLP tasks.  This focus on applied tasks is the most significant difference between spaCy and NLTK, which is designed to be a teaching and research tool. The shift of focus from NLP research to applied NLP has several important outcomes.  

First, the goal of a spaCy model is not state of the art performance (SOTA). spaCy's developers, Matthew Honnibal and Ines Montani, will frequently favor speed, memory usage, and practicality over small gains in accuracy. The goal is a practical, opinionated tool that delivers results in production.  As a result, spaCy offers a library that works well on laptops and consumer devices. It works efficiently on a CPU and does not require GPUs.  The organizers hope that participants will continue to work on their models and share their knowledge outside of the workshops.  For our methods to be accessible, we cannot require research computing resources. Whenever possible, we tailor our exercises and tasks such that they can be performed on a standard laptop or Colab Notebook with 16GB of memory.  spaCy is also a very extensible library, which makes it well suited to working with TEI.  

Additionally, spaCy offers several useful command-line tools for language model training. The convert CLI converts linguistic data from the CoNLL-U format into JSON for training in spaCy.  There is also a debug data command that will validate and inspect training data.  This is an extremely useful tool that offers users some bearing on gaps in the data and how the model is likely to perform given the current data.  Prodigy offers a train-curve recipe that helps users to assess if additional data would lead to significant improvement in model accuracy. Finally, there is a train command that loads a base spaCy language object and then either creates or updates a statistical language model using the data provided.  While it is possible to add and train individual pipelines, this offers a simple CLI for users to create an initial language model from data with parser, tagger and ner pipelines from the CoNLL-U data.   
