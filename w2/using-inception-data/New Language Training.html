
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>22. üåø The New Language Project &#8212; New Languages for NLP</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="23. üèãÔ∏è Weights and Biases" href="../wandb.html" />
    <link rel="prev" title="21. The Config File" href="../config.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">New Languages for NLP</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Welcome!
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Prerequisite Knowledge
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../prep/introduction.html">
   1. Getting Ready for the Workshops
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prep/ml.html">
   2. Neural Networks and Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prep/nlp.html">
   3. NLP and spaCy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prep/fairuse.html">
   4. Corpus Documentation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Prerequisite Skills
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../prep/data.html">
   5. Data Formats
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prep/tei.html">
   6. Text Encoding Initiative (TEI)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prep/github.html">
   7. GitHub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prep/jupyter.html">
   8. Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Workshop I Annotation and Linguistic Data ~ June 21-25, 2021.
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../w1/overview.html">
   9. Welcome to Workshop I
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../w1/cadet.html">
   10. Cadet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../w1/cadet-notebook.html">
   11. Cadet the Notebook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../w1/inception.html">
   12. INCEpTION
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../w1/tokenization.html">
   13. Tokenization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../w1/ud.html">
   14. Universal features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../w1/InstituteGlossary.html">
   15. Institute Glossary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Workshop II Model Training ~ January 10-14, 2022
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   16. Welcome to Workshop II
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../prep.html">
   17. Preparation for Workshop II
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro-ml.html">
   18. Introduction to Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../practical-intro/Practical%20Introduction%20to%20Model%20Training.html">
   19. Practical Introduction to Model Training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../projects.html">
   20. The Project File
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../config.html">
   21. The Config File
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   22. üåø The New Language Project
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wandb.html">
   23. üèãÔ∏è Weights and Biases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../huggingface.html">
   24. ü§ó Hugging Face
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Workshop III  Presentations and Publications ~ May 12-13, 2022
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../w3/overview.html">
   25. Welcome to Workshop III
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/w2/using-inception-data/New Language Training.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/New-Languages-for-NLP/course-materials/gh-pages?urlpath=tree/w2/using-inception-data/New Language Training.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#install">
   22.1. Install
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#config">
   22.2. Config
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convert">
   22.3. Convert
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split">
   22.4. Split
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#debug">
   22.5. Debug
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train">
   22.6. Train
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate">
   22.7. Evaluate
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#package">
   22.8. Package
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="the-new-language-project">
<h1><span class="section-number">22. </span>üåø The New Language Project<a class="headerlink" href="#the-new-language-project" title="Permalink to this headline">¬∂</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/drive/1iC2YF3s30e0lDxdGmegRKS8iggLldMMH?usp=sharing"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p>For our workshops, we‚Äôve created a spaCy project file for you that will:</p>
<ul class="simple">
<li><p>fetch your language data from GitHub</p></li>
<li><p>convert and prepare the data for model training</p></li>
<li><p>train a model for your new language</p></li>
<li><p>package and publish your new model</p></li>
</ul>
<p>This workflow can be adapted to meet the specific needs of your project. In this section, we will walk through the various sections and scripts of the project.  We‚Äôve made some choices on your behalf. They may be right, or you may want to change things. Let‚Äôs see what‚Äôs there.</p>
<p>In your language team‚Äôs GitHub repository, you‚Äôll find a <code class="docutils literal notranslate"><span class="pre">newlang_project</span></code> folder that contains a <code class="docutils literal notranslate"><span class="pre">project.yml</span></code> file. In the next cell, we‚Äôre going to clone the repository and fetch the project‚Äôs assets. If your repository is private, you‚Äôll need to get a developer key and enter it as <code class="docutils literal notranslate"><span class="pre">git_access_token</span></code>.  Otherwise, just enter your repository‚Äôs name under <code class="docutils literal notranslate"><span class="pre">repo_name</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>newlang_project
‚îÇ   README.md
‚îÇ   project.yml    
‚îÇ
‚îî‚îÄ‚îÄ‚îÄscripts
    ‚îÇ   convert.py
    ‚îÇ   split.py
    ‚îÇ   update_config.py
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># temp to clear project folder</span>
<span class="o">!</span>rm -rf /srv/projects/course-materials/w2/using-inception-data/newlang_project
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">repo_name</span> <span class="o">=</span> <span class="s2">&quot;repo-template&quot;</span>
<span class="n">private_repo</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">git_access_token</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="o">!</span>rm -rf /content/newlang_project
<span class="o">!</span>rm -rf <span class="nv">$repo_name</span>
<span class="k">if</span> <span class="n">private_repo</span><span class="p">:</span>
    <span class="n">git_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://</span><span class="si">{</span><span class="n">git_access_token</span><span class="si">}</span><span class="s2">@github.com/New-Languages-for-NLP/</span><span class="si">{</span><span class="n">repo_name</span><span class="si">}</span><span class="s2">/&quot;</span>
    <span class="o">!</span>git clone <span class="nv">$git_url</span>  -b main
    <span class="o">!</span>cp -r ./<span class="nv">$repo_name</span>/newlang_project .  
    <span class="o">!</span>mkdir newlang_project/assets/
    <span class="o">!</span>mkdir newlang_project/configs/
    <span class="o">!</span>mkdir newlang_project/corpus/
    <span class="o">!</span>mkdir newlang_project/metrics/
    <span class="o">!</span>mkdir newlang_project/packages/
    <span class="o">!</span>mkdir newlang_project/training/
    <span class="o">!</span>mkdir newlang_project/assets/<span class="nv">$repo_name</span>
    <span class="o">!</span>cp -r ./<span class="nv">$repo_name</span>/* newlang_project/assets/<span class="nv">$repo_name</span>/
    <span class="o">!</span>rm -rf ./<span class="nv">$repo_name</span>
<span class="k">else</span><span class="p">:</span>
    <span class="o">!</span>python -m spacy project clone newlang_project --repo https://github.com/New-Languages-for-NLP/<span class="nv">$repo_name</span> --branch main
    <span class="o">!</span>python -m spacy project assets /srv/projects/course-materials/w2/using-inception-data/newlang_project
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-C2">‚úî Cloned &#39;newlang_project&#39; from New-Languages-for-NLP/repo-template</span>
/srv/projects/course-materials/w2/using-inception-data/newlang_project
<span class=" -Color -Color-C2">‚úî Your project is now ready!</span>
To fetch the assets, run:
python -m spacy project assets /srv/projects/course-materials/w2/using-inception-data/newlang_project
<span class=" -Color -Color-C4">‚Ñπ Fetching 1 asset(s)</span>
<span class=" -Color -Color-C2">‚úî Downloaded asset</span>
<span class=" -Color -Color-C2">/srv/projects/course-materials/w2/using-inception-data/newlang_project/assets/urban-giggle</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs start with the <strong>project.yml</strong> file in the newlang_project folder.</p>
<p>You‚Äôll find a <strong>metadata</strong> section that you can update however you like using the yaml format.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">title</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Train</span><span class="nv"> </span><span class="s">new</span><span class="nv"> </span><span class="s">language</span><span class="nv"> </span><span class="s">model</span><span class="nv"> </span><span class="s">from</span><span class="nv"> </span><span class="s">cadet</span><span class="nv"> </span><span class="s">and</span><span class="nv"> </span><span class="s">inception</span><span class="nv"> </span><span class="s">data&quot;</span><span class="w"></span>
<span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;This</span><span class="nv"> </span><span class="s">project</span><span class="nv"> </span><span class="s">template</span><span class="nv"> </span><span class="s">lets</span><span class="nv"> </span><span class="s">you</span><span class="nv"> </span><span class="s">train</span><span class="nv"> </span><span class="s">a</span><span class="nv"> </span><span class="s">part-of-speech</span><span class="nv"> </span><span class="s">tagger,</span><span class="nv"> </span><span class="s">morphologizer</span><span class="nv"> </span><span class="s">and</span><span class="nv"> </span><span class="s">dependency</span><span class="nv"> </span><span class="s">parser</span><span class="nv"> </span><span class="s">from</span><span class="nv"> </span><span class="s">your</span><span class="nv"> </span><span class="s">cadet</span><span class="nv"> </span><span class="s">and</span><span class="nv"> </span><span class="s">inception</span><span class="nv"> </span><span class="s">data.&quot;</span><span class="w"></span>
</pre></div>
</div>
<p>The <strong>vars</strong> section will have some information that is specific to your team.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">vars</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">config</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;config&quot;</span><span class="w"></span>
<span class="w">  </span><span class="nt">lang</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;yi&quot;</span><span class="w"></span>
<span class="w">  </span><span class="nt">treebank</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;yiddish&quot;</span><span class="w"></span>
<span class="w">  </span><span class="nt">test_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span><span class="w"></span>
<span class="w">  </span><span class="nt">n_sents</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"></span>
<span class="w">  </span><span class="nt">random_state</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">11</span><span class="w"></span>
<span class="w">  </span><span class="nt">package_name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Yiddish</span><span class="nv"> </span><span class="s">NewNLP</span><span class="nv"> </span><span class="s">Model</span><span class="nv"> </span><span class="s">May</span><span class="nv"> </span><span class="s">2022&quot;</span><span class="w"></span>
<span class="w">  </span><span class="nt">package_version</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;0.1&quot;</span><span class="w"></span>
<span class="w">  </span><span class="nt">wandb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span>
<span class="w">  </span><span class="nt">gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span><span class="w"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">config</span></code> setting is the name and location of the config file.  We‚Äôll just have <code class="docutils literal notranslate"><span class="pre">config.cfg</span></code> in the project directory, so nothing fancy here.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lang</span></code> is the ISO-style abbreviation for your language.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">treebank</span></code> is the name of your language‚Äôs repository (and is ususally the same as the language name).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">test_size</span></code> is the percentage of data that you want to set aside for model validation and testing. An 80/20 split is a good place to start, so you‚Äôll see it set initially to <code class="docutils literal notranslate"><span class="pre">0.2</span></code>. For more, this <a class="reference external" href="https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio">stackoverflow discussion</a> is very informative.</p></li>
<li><p>To evenly distribute your texts between the training and validation datasets, we split each text into blocks of 10 sentences. This is defined by the <code class="docutils literal notranslate"><span class="pre">n_sents</span></code> variable.</p></li>
<li><p>To ensure that the test and train split is consistent and reproducible, we use a number called <code class="docutils literal notranslate"><span class="pre">random_state</span></code>. More <a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-random_state">here</a>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">package_name</span></code> is used during packaging. It sets the package‚Äôs metadata name. Basically, what is the name of your language model?</p></li>
<li><p>Similarly, <code class="docutils literal notranslate"><span class="pre">package_version</span></code> sets the package metadata for version.</p></li>
<li><p>spaCy comes with some basic ways to log training data.  However, <a class="reference external" href="https://wandb.ai/">Weights and Biases</a> provides an excellent way to record, manage and share experiment data. You‚Äôll need to create a free account and get an API key to use bandb. When set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, your project will use bandb (we highly recommend it). You can change this to <code class="docutils literal notranslate"><span class="pre">false</span></code> if you prefer spaCy‚Äôs default logging.</p></li>
<li><p>Finally, model training with graphics chips (GPUs) is often faster than with a standard CPU. We recommend using Colab for their free GPUs.  In such a case, you‚Äôd change <code class="docutils literal notranslate"><span class="pre">-1</span></code> (CPU) to <code class="docutils literal notranslate"><span class="pre">0</span></code> (the GPU id).</p></li>
</ul>
<p><strong>Assets</strong> is configured to use your language repo name to fetch project data from GitHub.  It will save all that data in the <code class="docutils literal notranslate"><span class="pre">assets/your-language-name</span></code> folder.</p>
<p>The <strong>commands</strong> section is the heart of the project file.  Let‚Äôs take some time to understand each command and what it does.</p>
<hr class="docutils" />
<div class="section" id="install">
<h2><span class="section-number">22.1. </span>Install<a class="headerlink" href="#install" title="Permalink to this headline">¬∂</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">install</span></code> command in the next cell will read the files in the <code class="docutils literal notranslate"><span class="pre">2_new_language_object</span></code> directory and will install the customized spaCy language object that you created for your language in Cadet. The language object will tell spaCy how to break your texts into tokens and sentence spans.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install the custom language object from Cadet </span>
<span class="o">!</span>python -m spacy project run install /srv/projects/course-materials/w2/using-inception-data/newlang_project
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
<span class=" -Color -Color-Bold">================================== install ==================================</span>
Running command: rm -rf lang
Running command: mkdir lang
Running command: mkdir lang/yi
Running command: cp -r assets/urban-giggle/2_new_language_object/ lang/yi/yi
Running command: mv lang/yi/yi/setup.py lang/yi/
Running command: /srv/projects/course-materials/w2/venv/bin/python -m pip install -e lang/yi
Obtaining file:///srv/projects/course-materials/w2/using-inception-data/newlang_project/lang/yi
Installing collected packages: yi
  Attempting uninstall: yi
    Found existing installation: yi 0.0.0
    Uninstalling yi-0.0.0:
      Successfully uninstalled yi-0.0.0
  Running setup.py develop for yi
Successfully installed yi
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="config">
<h2><span class="section-number">22.2. </span>Config<a class="headerlink" href="#config" title="Permalink to this headline">¬∂</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">config</span></code> command creates a generic <code class="docutils literal notranslate"><span class="pre">config.cfg</span></code> file (for more on config files, see the <a class="reference external" href="https://new-languages-for-nlp.github.io/course-materials/w2/config.html">Config section</a> in these course materials).  It updates the <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">dev</span></code> settings in the config file to point to the <code class="docutils literal notranslate"><span class="pre">train.spacy</span></code> and <code class="docutils literal notranslate"><span class="pre">dev.spacy</span></code> files that are created by the <code class="docutils literal notranslate"><span class="pre">split</span></code> command.  If you‚Äôre using Weights and Biases, it will also change the <code class="docutils literal notranslate"><span class="pre">training</span> <span class="pre">logger</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m spacy project run config /srv/projects/course-materials/w2/using-inception-data/newlang_project
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
<span class=" -Color -Color-Bold">=================================== config ===================================</span>
Running command: /srv/projects/course-materials/w2/venv/bin/python -m spacy init config config.cfg --lang yi -F
<span class=" -Color -Color-C3">‚ö† To generate a more effective transformer-based config (GPU-only),</span>
<span class=" -Color -Color-C3">install the spacy-transformers package and re-run this command. The config</span>
<span class=" -Color -Color-C3">generated now does not use transformers.</span>
<span class=" -Color -Color-C4">‚Ñπ Generated config template specific for your use case</span>
- Language: yi
- Pipeline: tagger, parser, ner
- Optimize for: efficiency
- Hardware: CPU
- Transformer: None
<span class=" -Color -Color-C2">‚úî Auto-filled config with all values</span>
<span class=" -Color -Color-C2">‚úî Saved config</span>
config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
Running command: /srv/projects/course-materials/w2/venv/bin/python scripts/update_config.py urban-giggle false
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="convert">
<h2><span class="section-number">22.3. </span>Convert<a class="headerlink" href="#convert" title="Permalink to this headline">¬∂</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Convert</span></code> will fetch your CoNLL-U and CoNLL 2002 (ner) files from the <code class="docutils literal notranslate"><span class="pre">3_inception_export</span></code> folder.  It creates a spaCy Doc object for each text and then splits the Doc into separate documents with 10 sentences each. For each text file, the <code class="docutils literal notranslate"><span class="pre">convert</span></code> script will look for a CoNLL 2002 file with the same name.  If that text exists, it will add the named entity data in the file to the existing Doc objects. It will then save all the Docs to disk using the <code class="docutils literal notranslate"><span class="pre">.spacy</span></code> binary format.
The outcome is a <code class="docutils literal notranslate"><span class="pre">.spacy</span></code> for each text that includes the tokenization, sents, part of speech, lemma, morphology and named entity data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m spacy project run convert /srv/projects/course-materials/w2/using-inception-data/newlang_project -F
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
<span class=" -Color -Color-Bold">================================== convert ==================================</span>
Running command: /srv/projects/course-materials/w2/venv/bin/python scripts/convert.py assets/urban-giggle/3_inception_export 10 yi
<span class=" -Color -Color-C4">‚Ñπ Grouping every 10 sentences into a document.</span>
<span class=" -Color -Color-C2">‚úî Generated output file (49 documents):</span>
<span class=" -Color -Color-C2">corpus/converted/he_htb-ud-dev.spacy</span>
<span class=" -Color -Color-C4">‚Ñπ Grouping every 10 sentences into a document.</span>
<span class=" -Color -Color-C2">‚úî Generated output file (50 documents):</span>
<span class=" -Color -Color-C2">corpus/converted/he_htb-ud-test.spacy</span>
<span class=" -Color -Color-C4">‚Ñπ Grouping every 10 sentences into a document.</span>
<span class=" -Color -Color-C2">‚úî Generated output file (525 documents):</span>
<span class=" -Color -Color-C2">corpus/converted/he_htb-ud-train.spacy</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="split">
<h2><span class="section-number">22.4. </span>Split<a class="headerlink" href="#split" title="Permalink to this headline">¬∂</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">split</span></code> command loads all of the <code class="docutils literal notranslate"><span class="pre">.spacy</span></code> files and creates a list of Doc objects.  We then randomly shuffle them so that different kinds of text are evenly distibuted across the corpus.  Using a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"><code class="docutils literal notranslate"><span class="pre">test_train_split</span></code></a> function, we divide the corpus into a training and validation set. The split is determined by the <code class="docutils literal notranslate"><span class="pre">test_size</span></code> variable. The model will learn how to make accurate predictions using the training data. We then use the validation set to assess how well the model performs on completeley new and unseen data. We want the model to learn general rules and patterns rather than overfitting on one particular set of data. The validation set provides a measure of model improvement as part of the training process. Because the model has seen this data before, it‚Äôs no longer useful as a tool to evaluate the trained model‚Äôs performance.  So before we get started training, we also set aside 20% of the validation data to make a test set.  This final set of totally unseen data lets us measure how well the model has learned what we‚Äôve asked it to learn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m spacy project run split /srv/projects/course-materials/w2/using-inception-data/newlang_project -F
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
<span class=" -Color -Color-Bold">=================================== split ===================================</span>
Running command: /srv/projects/course-materials/w2/venv/bin/python scripts/split.py 0.2 11 yi
üöÇ Created 499 training docs
üòä Created 100 validation docs
üß™  Created 25 test docs
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="debug">
<h2><span class="section-number">22.5. </span>Debug<a class="headerlink" href="#debug" title="Permalink to this headline">¬∂</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">debug</span></code> command runs <code class="docutils literal notranslate"><span class="pre">spacy</span> <span class="pre">debug</span> <span class="pre">data</span></code>, which provides a good overview of your prepared data.  This can help identify problems that will lead to poor model training. It‚Äôs a good check-in and moment of reflection on the state of your data before moving forward. For more, see the <a class="reference external" href="https://spacy.io/api/cli#debug-data">spaCy docs</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m spacy project run debug  /srv/projects/course-materials/w2/using-inception-data/newlang_project
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
<span class=" -Color -Color-Bold">=================================== debug ===================================</span>
Running command: /srv/projects/course-materials/w2/venv/bin/python -m spacy debug data ./config.cfg

<span class=" -Color -Color-Bold">============================ Data file validation ============================</span>
<span class=" -Color -Color-C2">‚úî Pipeline can be initialized with data</span>
<span class=" -Color -Color-C2">‚úî Corpus is loadable</span>

<span class=" -Color -Color-Bold">=============================== Training stats ===============================</span>
Language: yi
Training pipeline: tok2vec, tagger, parser, ner
499 training docs
100 evaluation docs
<span class=" -Color -Color-C2">‚úî No overlap between training and evaluation data</span>
<span class=" -Color -Color-C3">‚ö† Low number of examples to train a new pipeline (499)</span>

<span class=" -Color -Color-Bold">============================== Vocab &amp; Vectors ==============================</span>
<span class=" -Color -Color-C4">‚Ñπ 130313 total word(s) in the data (15962 unique)</span>
<span class=" -Color -Color-C3">‚ö† 30077 misaligned tokens in the training data</span>
<span class=" -Color -Color-C3">‚ö† 5675 misaligned tokens in the dev data</span>
<span class=" -Color -Color-C4">‚Ñπ No word vectors present in the package</span>

<span class=" -Color -Color-Bold">========================== Named Entity Recognition ==========================</span>
<span class=" -Color -Color-C4">‚Ñπ 0 label(s)</span>
0 missing value(s) (tokens with &#39;-&#39; label)
<span class=" -Color -Color-C2">‚úî Good amount of examples for all labels</span>
<span class=" -Color -Color-C2">‚úî Examples without occurrences available for all labels</span>
<span class=" -Color -Color-C2">‚úî No entities consisting of or starting/ending with whitespace</span>

<span class=" -Color -Color-Bold">=========================== Part-of-speech Tagging ===========================</span>
<span class=" -Color -Color-C4">‚Ñπ 15 label(s) in train data</span>

<span class=" -Color -Color-Bold">============================= Dependency Parsing =============================</span>
<span class=" -Color -Color-C4">‚Ñπ Found 4714 sentence(s) with an average length of 27.6 words.</span>
<span class=" -Color -Color-C4">‚Ñπ Found 112 nonprojective train sentence(s)</span>
<span class=" -Color -Color-C4">‚Ñπ 36 label(s) in train data</span>
<span class=" -Color -Color-C4">‚Ñπ 52 label(s) in projectivized train data</span>
<span class=" -Color -Color-C3">‚ö† Low number of examples for label &#39;dislocated&#39; (10)</span>
<span class=" -Color -Color-C3">‚ö† Low number of examples for label &#39;csubj&#39; (1)</span>
<span class=" -Color -Color-C3">‚ö† Low number of examples for label &#39;discourse&#39; (2)</span>
<span class=" -Color -Color-C3">‚ö† Low number of examples for 13 label(s) in the projectivized</span>
<span class=" -Color -Color-C3">dependency trees used for training. You may want to projectivize labels such as</span>
<span class=" -Color -Color-C3">punct before training in order to improve parser performance.</span>

<span class=" -Color -Color-Bold">================================== Summary ==================================</span>
<span class=" -Color -Color-C2">‚úî 6 checks passed</span>
<span class=" -Color -Color-C3">‚ö† 10 warnings</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="train">
<h2><span class="section-number">22.6. </span>Train<a class="headerlink" href="#train" title="Permalink to this headline">¬∂</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">train</span></code> command is the moment we‚Äôve all been waiting for. Go ahead and press the launch button! üöÄ This step will train the model using the settings in the config file.</p>
<p>When training begins, you‚Äôll see a bunch of numbers. Let‚Äôs make sense of what they‚Äôre saying.</p>
<p>You‚Äôll see a list of what components are currently being trained.  <code class="docutils literal notranslate"><span class="pre">Pipeline:</span> <span class="pre">['tok2vec',</span> <span class="pre">'tagger',</span> <span class="pre">'parser',</span> <span class="pre">'ner']</span></code> Tok2vec are token embeddings or numerical representations of tokens that can be used efficiently by the model. The tagger will learn to predict part of speech values for your tokens. The parser will learn to predict grammatical structure. The ner component learns to predict named entities in the text.</p>
<p>For each of these components, spaCy will print training metrics. So let‚Äôs dive into this pile of forbidding verbiage and numbers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">E</span>    <span class="c1">#       LOSS TOK2VEC  LOSS TAGGER  LOSS PARSER  LOSS NER  TAG_ACC  DEP_UAS  DEP_LAS  SENTS_F  ENTS_F  ENTS_P  ENTS_R  SCORE</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">E</span></code> refers to the epoch. An epoch is one complete pass of all the data through the model. You can set the number of epochs to complete during training or let spaCy optimize the number of epochs automatically (this is the default).</p></li>
<li><p>Every 200 examples, spaCy outputs accuracy scores in the <code class="docutils literal notranslate"><span class="pre">#</span></code> column.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LOSS</span></code> refers to training loss. Loss is a measure of error. During training, the model will try to learn how to improve its predictions. Decreasing loss can suggest that the model is learning and improving.  If the loss value flattens or plateaus, the model has probably stopped learning or reached the best result for a given set of parameters and data.  You will find a loss measure for each of the pipeline components being trained. If the loss varies greatly and looks like a zigzag, the model is struggling to improve its predictions in a deliberate manner. <code class="docutils literal notranslate"><span class="pre">LOSS</span> <span class="pre">TOK2VEC</span>&#160; <span class="pre">LOSS</span> <span class="pre">TAGGER</span>&#160; <span class="pre">LOSS</span> <span class="pre">PARSER</span>&#160; <span class="pre">LOSS</span> <span class="pre">NER</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TAG_ACC</span></code> refers to the accuracy of the tagger component. <a class="reference external" href="https://developers.google.com/machine-learning/glossary#accuracy">Accuracy</a> is the number of correct predictions divided by the total number of predictions made.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DEP_UAS</span></code> and  <code class="docutils literal notranslate"><span class="pre">DEP_LAS</span></code> are the unlabeled attachment score (UAS) and labeled attachment score (LAS) for the dependency parser. This is a measure of how many times the model correctly predicted the correct head.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SENTS_F</span></code> gives the model‚Äôs <a class="reference external" href="https://en.wikipedia.org/wiki/F-score">f-score</a> for sentence prediction.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ENTS_F</span>&#160; <span class="pre">ENTS_P</span>&#160; <span class="pre">ENTS_R</span></code> relate to the model‚Äôs predictions of named entities. The f-score is the mean of precision and recall.</p></li>
<li><p>Finally, spaCy logs a <code class="docutils literal notranslate"><span class="pre">SCORE</span></code> for the model‚Äôs predictions overall. This gives a rough number for the model‚Äôs overall accuracy.  As a general rule, increasing numbers means that the model is improving. By default, spaCy will end training when the score stops rising.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m spacy project run train /srv/projects/course-materials/w2/using-inception-data/newlang_project
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
<span class=" -Color -Color-Bold">=================================== train ===================================</span>
Running command: /srv/projects/course-materials/w2/venv/bin/python -m spacy train config.cfg --output training/urban-giggle --gpu-id -1 --nlp.lang=yi
<span class=" -Color -Color-C4">‚Ñπ Saving to output directory: training/urban-giggle</span>
<span class=" -Color -Color-C4">‚Ñπ Using CPU</span>

<span class=" -Color -Color-Bold">=========================== Initializing pipeline ===========================</span>
[2021-12-30 21:32:00,090] [INFO] Set up nlp object from config
[2021-12-30 21:32:00,097] [INFO] Pipeline: [&#39;tok2vec&#39;, &#39;tagger&#39;, &#39;parser&#39;]
[2021-12-30 21:32:00,100] [INFO] Created vocabulary
[2021-12-30 21:32:00,101] [INFO] Finished initializing nlp object
[2021-12-30 21:32:04,936] [INFO] Initialized pipeline components: [&#39;tok2vec&#39;, &#39;tagger&#39;, &#39;parser&#39;]
<span class=" -Color -Color-C2">‚úî Initialized pipeline</span>

<span class=" -Color -Color-Bold">============================= Training pipeline =============================</span>
<span class=" -Color -Color-C4">‚Ñπ Pipeline: [&#39;tok2vec&#39;, &#39;tagger&#39;, &#39;parser&#39;]</span>
<span class=" -Color -Color-C4">‚Ñπ Initial learn rate: 0.001</span>
E    #       LOSS TOK2VEC  LOSS TAGGER  LOSS PARSER  TAG_ACC  DEP_UAS  DEP_LAS  SENTS_F  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  ------------  -----------  -----------  -------  -------  -------  -------  ------  ------  ------  ------
  0       0          0.00       145.60       431.08    22.31     3.87     3.16     0.09    0.00    0.00    0.00    0.09
  0     200       2489.76     11513.39     26848.70    51.98    22.62    15.10    60.33    0.00    0.00    0.00    0.24
  0     400       4685.01      6464.16     22632.98    56.50    25.11    19.89    77.27    0.00    0.00    0.00    0.26
<span class=" -Color -Color-C2">‚úî Saved pipeline to output directory</span>
training/urban-giggle/model-last
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="evaluate">
<h2><span class="section-number">22.7. </span>Evaluate<a class="headerlink" href="#evaluate" title="Permalink to this headline">¬∂</a></h2>
<p>The <strong>evaluate</strong> command takes the trained model and tests it with the test data.  Recall that these are examples that the model has never seen, so they provide the best measure of its performance. The output will be saved as a json file in the metrics folder.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate the model </span>
<span class="o">!</span>python -m spacy project run evaluate /srv/projects/course-materials/w2/using-inception-data/newlang_project
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
<span class=" -Color -Color-Bold">================================== evaluate ==================================</span>
Running command: /srv/projects/course-materials/w2/venv/bin/python -m spacy evaluate ./training/urban-giggle/model-best ./corpus/converted/test.spacy --output ./metrics/urban-giggle.json --gpu-id -1
<span class=" -Color -Color-C4">‚Ñπ Using CPU</span>

<span class=" -Color -Color-Bold">================================== Results ==================================</span>

TOK      80.58
TAG      55.30
UAS      23.93
LAS      18.56
SENT P   74.31
SENT R   85.60
SENT F   79.55
SPEED    19651


<span class=" -Color -Color-Bold">=============================== LAS (per type) ===============================</span>

                      P       R       F
det               72.41    3.12    5.97
nsubj             48.22   27.78   35.25
flat:name         26.79   32.97   29.56
root              61.47   56.80   59.04
case:acc          88.46   28.40   42.99
obj               39.29   13.75   20.37
case:gen          86.79   27.88   42.20
nmod:poss         42.31    8.09   13.58
case              89.58   11.78   20.82
obl               43.40    5.24    9.35
nmod              28.00    2.32    4.28
amod              43.48   20.41   27.78
mark              70.27   14.29   23.74
acl:relcl         10.42    5.21    6.94
compound:smixut   53.19    8.71   14.97
dep               28.57    1.87    3.51
fixed             29.41    7.58   12.05
appos              4.26    6.67    5.19
nummod            95.16   52.21   67.43
cop               77.42   44.44   56.47
parataxis          0.00    0.00    0.00
advcl              0.00    0.00    0.00
advmod            59.84   38.38   46.77
ccomp             15.15   14.71   14.93
xcomp             32.20   44.19   37.25
acl               50.00    8.70   14.81
cc                53.85    3.87    7.22
conj              19.67    5.77    8.92
csubj              0.00    0.00    0.00
nsubj:cop         33.33    5.88   10.00
compound:affix     0.00    0.00    0.00
aux               62.50   38.46   47.62

<span class=" -Color -Color-C2">‚úî Saved results to metrics/urban-giggle.json</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="package">
<h2><span class="section-number">22.8. </span>Package<a class="headerlink" href="#package" title="Permalink to this headline">¬∂</a></h2>
<p>Finally, the <strong>package</strong> command saves your trained model in a single tar file that can be shared and installed on other computers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m spacy package ./newlang_project/training/urban-giggle/model-last ./export 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-C4">‚Ñπ Building package artifacts: sdist</span>
<span class=" -Color -Color-C2">‚úî Loaded meta.json from file</span>
newlang_project/training/urban-giggle/model-last/meta.json
<span class=" -Color -Color-C2">‚úî Generated README.md from meta.json</span>
<span class=" -Color -Color-C2">‚úî Successfully created package &#39;yi_pipeline-0.0.0&#39;</span>
export/yi_pipeline-0.0.0
running sdist
running egg_info
creating yi_pipeline.egg-info
writing yi_pipeline.egg-info/PKG-INFO
writing dependency_links to yi_pipeline.egg-info/dependency_links.txt
writing entry points to yi_pipeline.egg-info/entry_points.txt
writing requirements to yi_pipeline.egg-info/requires.txt
writing top-level names to yi_pipeline.egg-info/top_level.txt
writing manifest file &#39;yi_pipeline.egg-info/SOURCES.txt&#39;
reading manifest file &#39;yi_pipeline.egg-info/SOURCES.txt&#39;
reading manifest template &#39;MANIFEST.in&#39;
warning: no files found matching &#39;LICENSE&#39;
warning: no files found matching &#39;LICENSES_SOURCES&#39;
writing manifest file &#39;yi_pipeline.egg-info/SOURCES.txt&#39;
running check
warning: check: missing required meta-data: url

warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied

creating yi_pipeline-0.0.0
creating yi_pipeline-0.0.0/yi_pipeline
creating yi_pipeline-0.0.0/yi_pipeline.egg-info
creating yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0
creating yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/parser
creating yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/tagger
creating yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/tok2vec
creating yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/vocab
copying files to yi_pipeline-0.0.0...
copying MANIFEST.in -&gt; yi_pipeline-0.0.0
copying README.md -&gt; yi_pipeline-0.0.0
copying meta.json -&gt; yi_pipeline-0.0.0
copying setup.py -&gt; yi_pipeline-0.0.0
copying yi_pipeline/__init__.py -&gt; yi_pipeline-0.0.0/yi_pipeline
copying yi_pipeline/meta.json -&gt; yi_pipeline-0.0.0/yi_pipeline
copying yi_pipeline.egg-info/PKG-INFO -&gt; yi_pipeline-0.0.0/yi_pipeline.egg-info
copying yi_pipeline.egg-info/SOURCES.txt -&gt; yi_pipeline-0.0.0/yi_pipeline.egg-info
copying yi_pipeline.egg-info/dependency_links.txt -&gt; yi_pipeline-0.0.0/yi_pipeline.egg-info
copying yi_pipeline.egg-info/entry_points.txt -&gt; yi_pipeline-0.0.0/yi_pipeline.egg-info
copying yi_pipeline.egg-info/not-zip-safe -&gt; yi_pipeline-0.0.0/yi_pipeline.egg-info
copying yi_pipeline.egg-info/requires.txt -&gt; yi_pipeline-0.0.0/yi_pipeline.egg-info
copying yi_pipeline.egg-info/top_level.txt -&gt; yi_pipeline-0.0.0/yi_pipeline.egg-info
copying yi_pipeline/yi_pipeline-0.0.0/README.md -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0
copying yi_pipeline/yi_pipeline-0.0.0/config.cfg -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0
copying yi_pipeline/yi_pipeline-0.0.0/meta.json -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0
copying yi_pipeline/yi_pipeline-0.0.0/tokenizer -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0
copying yi_pipeline/yi_pipeline-0.0.0/parser/cfg -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/parser
copying yi_pipeline/yi_pipeline-0.0.0/parser/model -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/parser
copying yi_pipeline/yi_pipeline-0.0.0/parser/moves -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/parser
copying yi_pipeline/yi_pipeline-0.0.0/tagger/cfg -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/tagger
copying yi_pipeline/yi_pipeline-0.0.0/tagger/model -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/tagger
copying yi_pipeline/yi_pipeline-0.0.0/tok2vec/cfg -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/tok2vec
copying yi_pipeline/yi_pipeline-0.0.0/tok2vec/model -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/tok2vec
copying yi_pipeline/yi_pipeline-0.0.0/vocab/key2row -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/vocab
copying yi_pipeline/yi_pipeline-0.0.0/vocab/lookups.bin -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/vocab
copying yi_pipeline/yi_pipeline-0.0.0/vocab/strings.json -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/vocab
copying yi_pipeline/yi_pipeline-0.0.0/vocab/vectors -&gt; yi_pipeline-0.0.0/yi_pipeline/yi_pipeline-0.0.0/vocab
Writing yi_pipeline-0.0.0/setup.cfg
creating dist
Creating tar archive
removing &#39;yi_pipeline-0.0.0&#39; (and everything under it)
<span class=" -Color -Color-C2">‚úî Successfully created zipped Python package</span>
export/yi_pipeline-0.0.0/dist/yi_pipeline-0.0.0.tar.gz
</pre></div>
</div>
</div>
</div>
<p>Keep in mind that you‚Äôll need some persistence and patience along the way. You‚Äôll probably need to run multiple experiments before you find the right blend of data and parameters to create a final product.  The instructors are happy to help along the way and we look forward to learning together with you. When all commands are successfully run, you will have converted your text annotations from inception and language object from Cadet into a trained statistical language model that can be loaded with spaCy for a large variety of research tasks.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./w2/using-inception-data"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../config.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">21. </span>The Config File</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../wandb.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">23. </span>üèãÔ∏è Weights and Biases</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Natalia Ermolaev, Andrew Janco, Toma Tasovac, Quinn Dombrowski, David Lassner<br/>
        
          <div class="extra_footer">
            <p>
<a target="_blank" href="https://www.neh.gov/divisions/odh"><img style="height:10%; width:10%" src="https://www.neh.gov/sites/default/files/inline-files/NEH-Horizontal-Stk-Seal-Black820.jpg" /></a>
<a target="_blank" href="https://cdh.princeton.edu"><img style="height:10%; width:10%" src="https://cdh.princeton.edu/static/img/CDH_logo.svg" /></a>
<a target="_blank" href="https://www.dariah.eu/"><img style="height:19%; width:19%" src="https://www.dariah.eu/wp-content/uploads/2017/02/logo.png" /></a>

</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>