{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16cdd475",
   "metadata": {},
   "source": [
    "# Practical Introduction to Model Training\n",
    "\n",
    "**In this notebook, we will train a spaCy named entity recognition model (NER) using data from [LitBank](https://github.com/dbamman/litbank), an annotated dataset of 100 works of English-language fiction.**\n",
    "\n",
    "Steps:  \n",
    "âœ… Load annotation data from LitBank  \n",
    "âœ… Create train and validation sets  \n",
    "âœ… Train NER from scratch using only the EN language object  \n",
    "âœ… Visualize the results and compare the model's predictions against the original data  \n",
    "âœ… Is the model sufficiently useful for research? What would need to be improved and changed?  \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ndN5qqGF-ICayAeZBKEGp7Qqi2-bTvu6?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b877b1a0",
   "metadata": {},
   "source": [
    "## Installing dependencies & loading data\n",
    "First, we install spaCy (to train the model), sklearn (to split the data for training), and tqdm (for a nice progress bar).\n",
    "\n",
    "We also clone the GitHub repo with the LitBank data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install libraries\n",
    "!pip install spacy sklearn tqdm\n",
    "#Clone LitBank\n",
    "!git clone https://github.com/dbamman/litbank.git\n",
    "import spacy\n",
    "#Show what version of spaCy we're using\n",
    "print(f'Using spaCy version {spacy.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d310c",
   "metadata": {},
   "source": [
    "Next, we creat a list of the text files in the `litbank/entities/brat` directory and display the number of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79f27be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] imported 100 files\n"
     ]
    }
   ],
   "source": [
    "#Imports the Path library\n",
    "from pathlib import Path\n",
    "#Moves to the path litbank/entities/brat\n",
    "entities_path = Path.cwd() / 'litbank' / 'entities' / 'brat'\n",
    "#Creates a list of text files in the path above\n",
    "text_files = [f for f in entities_path.iterdir() if f.suffix == '.txt']\n",
    "#Counts how many text files there are\n",
    "assert len(text_files) == 100\n",
    "#Show how many text files have been imported\n",
    "print(f'[*] imported {len(text_files)} files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208c5af",
   "metadata": {},
   "source": [
    "## Process LitBank data\n",
    "Here, we run each of the LitBank text files through spaCy, but only using the sentenceizer (i.e. not all the other pieces of the default English pipeline, because we want to train a new model, not use its existing predictions). We also extract each of the annotations in the LitBank text files (which should refer to people, places, etc.) and add them to an entity list for that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd119fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each file, create a Doc object and add the annotation data to doc.ents\n",
    "# our output is a list of Doc objects \n",
    "#Import spaCy, tqdm, and various utilities from spaCy\n",
    "import spacy \n",
    "from tqdm.notebook import tqdm\n",
    "from spacy.tokens import Span, DocBin\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "#Creates a list of Doc objects that are the output from spaCy\n",
    "docs = []\n",
    "\n",
    "#Use a blank spaCy model\n",
    "nlp = spacy.blank(\"en\")\n",
    "#Add the stentencizer ot break it up into sentences\n",
    "nlp.add_pipe('sentencizer') # used in training assessment\n",
    "\n",
    "#With each text file, while showing a progress bar\n",
    "for text_file in tqdm(text_files):\n",
    "    #Read the file\n",
    "    doc = nlp(text_file.read_text())\n",
    "    #Create a file for the extracted annotations\n",
    "    annotation_file = (entities_path / (text_file.stem +'.ann'))\n",
    "    #Split the annotations by new lines\n",
    "    annotations = annotation_file.read_text().split('\\n')\n",
    "    #Create a list for the entities\n",
    "    ents = []\n",
    "    #For each annotation\n",
    "    for annotation in annotations[:-1]:\n",
    "        #Split the data based on tab characters to seaprate label, start, and end\n",
    "        label, start, end = annotation.split('\\t')[1].split()\n",
    "        #Span is the text in the doc corresponding to the annotation\n",
    "        span = doc.char_span(int(start), int(end), label=label)\n",
    "        #Handles errors\n",
    "        if span: # when start and end do not match a valid string, spaCy returns a NoneType span\n",
    "            ents.append(span)\n",
    "    #Removes duplicated or overlapping words\n",
    "    filtered = filter_spans(ents)\n",
    "    #The entities we want are the filtered list\n",
    "    doc.ents = filtered\n",
    "    #Append the spaCy-analyzed text to the list of docs\n",
    "    docs.append(doc)\n",
    "    \n",
    "\n",
    "assert len(docs) == 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a9955",
   "metadata": {},
   "source": [
    "## Split data into sets for training and validation\n",
    "We don't want to use all the data for training, because that would leave us without any data to use for checking the model's accuracy. The *training* data is what the model actually learns from; the *validation* data is the data that's used to choose the best model from multiple training runs; the *test* data is the \"gold standard\" of \"right\" answers.\n",
    "\n",
    "If you read general-purpose descriptions of the different data sets for model training, you may see references to *hyperparamters* (like the \"learning rate\"). spaCy's built-in model training provides sensible defaults that you don't necessarily need to modify, but if you're interested in the details of what *could* be modified, you can check the [documentation about the training config file](https://spacy.io/usage/training#config)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e60eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš‚ Created 90 training docs\n",
      "ðŸ˜Š Created 7 validation docs\n",
      "ðŸ§ª Created 3 test docs\n"
     ]
    }
   ],
   "source": [
    "# Split the data into sets for training and validation \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split the data into the training set (90%) and validation set (10%)\n",
    "train_set, validation_set = train_test_split(docs, test_size=0.1)\n",
    "#Split the validation set into the actual validation set (70%) and test set (30%)\n",
    "validation_set, test_set = train_test_split(validation_set, test_size=0.3)\n",
    "#Print how many docs are in each set\n",
    "print(f'ðŸš‚ Created {len(train_set)} training docs')\n",
    "print(f'ðŸ˜Š Created {len(validation_set)} validation docs')\n",
    "print(f'ðŸ§ª Created {len(test_set)} test docs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5884580f",
   "metadata": {},
   "source": [
    "### Save the data sets\n",
    "From here, we save the training, validation, and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4afb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import DocBin, a format for saving a collection of spaCy Doc objects\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "#Define a DocBin for training data\n",
    "train_db = DocBin()\n",
    "#For each doc in the training set\n",
    "for doc in train_set:\n",
    "    #Add it to the training DocBin\n",
    "    train_db.add(doc)\n",
    "#Save the resulting file\n",
    "train_db.to_disk(\"./train.spacy\")\n",
    "\n",
    "# Define a DocBin for validation data, and do the same as above\n",
    "validation_db = DocBin()\n",
    "for doc in validation_set:\n",
    "    validation_db.add(doc)\n",
    "validation_db.to_disk(\"./dev.spacy\") \n",
    "\n",
    "# Define a DocBin for test data, and do the same as above\n",
    "test_db = DocBin()\n",
    "for doc in test_set:\n",
    "    test_db.add(doc)   \n",
    "test_db.to_disk(\"./test.spacy\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc929b84",
   "metadata": {},
   "source": [
    "Here, we check to make sure the files all exist and are of reasonable sizes given the way we split them (90% training, then splitting that remaining 10% into 70% validation and 30% test.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc36b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root  115753 Dec 23 08:20 dev.spacy\r\n",
      "-rw-r--r-- 1 root root   53751 Dec 23 08:20 test.spacy\r\n",
      "-rw-r--r-- 1 root root 1406959 Dec 23 08:20 train.spacy\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al train.spacy dev.spacy test.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b70be",
   "metadata": {},
   "source": [
    "## Create training configuration file\n",
    "Here, we create the configuration file we'll need to actually run the training. We're using English language, the named-entity recognition (NER) pipeline, and otherwise just the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a96434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3mâš  To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2mâœ” Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2mâœ” Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy init config ./config.cfg --lang en --pipeline ner -F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6c41d",
   "metadata": {},
   "source": [
    "## Model training\n",
    "The following code starts the training. The training output goes into a directory called `output`, and we define the paths to the training (train.spacy) and the validation (dev.spacy) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6d34ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mâ„¹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-12-23 08:22:05,786] [INFO] Set up nlp object from config\n",
      "[2021-12-23 08:22:05,792] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-12-23 08:22:05,794] [INFO] Created vocabulary\n",
      "[2021-12-23 08:22:05,795] [INFO] Finished initializing nlp object\n",
      "[2021-12-23 08:22:11,376] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2mâœ” Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mâ„¹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00   1072.88    0.00    0.00    0.00    0.00\n",
      "  2     200      18889.69  63358.78   35.62   28.97   46.21    0.36\n",
      "  4     400      11414.18  27850.79   53.58   60.92   47.83    0.54\n",
      "  6     600      24399.51  23338.55   54.53   64.79   47.08    0.55\n",
      "  8     800      20359.37  18970.20   57.03   62.17   52.67    0.57\n",
      " 11    1000       6056.26  15459.09   56.76   65.95   49.81    0.57\n",
      " 13    1200       6623.85  13355.36   59.69   62.62   57.02    0.60\n",
      " 15    1400       6450.33  10892.70   63.05   67.52   59.13    0.63\n",
      " 17    1600       8249.34  10429.20   61.55   68.65   55.78    0.62\n",
      " 20    1800       8022.00   8933.03   58.64   59.82   57.52    0.59\n",
      " 22    2000      10772.98   8298.90   59.52   62.85   56.52    0.60\n",
      " 24    2200       9276.31   7258.57   58.76   61.78   56.02    0.59\n",
      " 26    2400       6356.31   5919.32   57.84   60.22   55.65    0.58\n",
      " 28    2600       7711.42   5918.36   58.36   63.77   53.79    0.58\n",
      " 31    2800      11050.54   5581.69   56.84   61.72   52.67    0.57\n",
      " 33    3000       8032.93   4899.75   56.33   60.37   52.80    0.56\n",
      "\u001b[38;5;2mâœ” Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config.cfg --output ./output --paths.train train.spacy --paths.dev dev.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aaf2df",
   "metadata": {},
   "source": [
    "## Test the new model\n",
    "Finally, we can check how the model we just trained performs, using the test data set for comparison. The closer the model results are to the human-annotated test set, the better the model is performing. We'll start with running the model on a random exerpt from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbd894df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">CHAPTER I At sunset hour \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the forest\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " was still , lonely , sweet with tang of fir and spruce , blazing in gold and red and green ; and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the man who glided on under the great trees seemed to blend with\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the colors\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " and , disappearing , to have become a part of the wild woodland .</br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Old Baldy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " , highest of the White Mountains , stood up round and bare , rimmed bright gold in the last glow of the setting sun .</br>Then , as the fire dropped behind the domed peak , a change </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Imports the random library to choose a random exerpt.\n",
    "import random\n",
    "#Displacy shows a nice visualization of spaCy data, including entities on text\n",
    "from spacy import displacy \n",
    "\n",
    "#Load the model we just trained\n",
    "new_nlp = spacy.load(\"output/model-last\")\n",
    "#Pick a random exerpt from the test data set.\n",
    "val_doc = random.choice(test_set)\n",
    "#Run the new model on the random exerpt\n",
    "doc = new_nlp(val_doc.text)\n",
    "\n",
    "#Show the first 100 words of the random document.\n",
    "displacy.render(doc[:100], jupyter=True, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdee305",
   "metadata": {},
   "source": [
    "To compare, let's display the original, human-generated annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01af332a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">CHAPTER I At sunset hour \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the forest\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " was still , lonely , sweet with tang of fir and spruce , blazing in gold and red and green ; and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the man who glided on under the great trees\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " seemed to blend with the colors and , disappearing , to have become a part of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the wild woodland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " .</br>\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Old Baldy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " , highest of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the White Mountains\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " , stood up round and bare , rimmed bright gold in the last glow of the setting sun .</br>Then , as the fire dropped behind the domed peak , a change </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the original annotations in the same style\n",
    "displacy.render(val_doc[:100], jupyter=True, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf8db7",
   "metadata": {},
   "source": [
    "It's not always easy to see the differences right away: walk through the human-annotated text, entity by entity, and then check what happened with the model at that same point in the text. Some common errors include getting the entity right but the label wrong (e.g. switching LOC/PER), and including too many words in the entity, in addition to just missing the entity entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9fb5a0",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Is the model sufficiently useful for research? What would need to be improved and changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6618a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy evaluate output/model-last test.spacy --output litbank.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
