{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16cdd475",
   "metadata": {},
   "source": [
    "### Outline\n",
    "#### Goal is to train spaCy NER from litbank data \n",
    "✅ Load annotation data from LitBank  \n",
    "✅ Create train and validation sets  \n",
    "✅ Train NER from scratch using only language object  \n",
    "✅ Assess results for various approaches  \n",
    "✅ Where do we see improvement? When is the model sufficiently useful in research? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f0613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./venv/lib/python3.8/site-packages (3.2.1)\n",
      "Requirement already satisfied: sklearn in ./venv/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.8/site-packages (4.62.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./venv/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.8/site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./venv/lib/python3.8/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./venv/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./venv/lib/python3.8/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in ./venv/lib/python3.8/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in ./venv/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./venv/lib/python3.8/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./venv/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in ./venv/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./venv/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.8/site-packages (from spacy) (44.0.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in ./venv/lib/python3.8/site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in ./venv/lib/python3.8/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./venv/lib/python3.8/site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in ./venv/lib/python3.8/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./venv/lib/python3.8/site-packages (from spacy) (1.21.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./venv/lib/python3.8/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.8/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.8/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./venv/lib/python3.8/site-packages (from packaging>=20.0->spacy) (3.0.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./venv/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in ./venv/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Cloning into 'litbank'...\n",
      "remote: Enumerating objects: 1179, done.\u001b[K\n",
      "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
      "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
      "remote: Total 1179 (delta 12), reused 104 (delta 5), pack-reused 1056\u001b[K\n",
      "Receiving objects: 100% (1179/1179), 40.71 MiB | 4.24 MiB/s, done.\n",
      "Resolving deltas: 100% (129/129), done.\n",
      "Updating files: 100% (1423/1423), done.\n",
      "Using spaCy version 3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy sklearn tqdm\n",
    "!git clone https://github.com/dbamman/litbank.git\n",
    "import spacy \n",
    "print(f'Using spaCy version {spacy.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79f27be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] imported 100 files\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "entities_path = Path.cwd() / 'litbank' / 'entities' / 'brat'\n",
    "\n",
    "text_files = [f for f in entities_path.iterdir() if f.suffix == '.txt']\n",
    "assert len(text_files) == 100\n",
    "print(f'[*] imported {len(text_files)} files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd119fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a920e518414a609e27386f743647c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for each file, create a Doc object and add the annotation data to doc.ents\n",
    "# our output is a list of Doc objects \n",
    "import spacy \n",
    "from tqdm.notebook import tqdm\n",
    "from spacy.tokens import Span, DocBin\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "\n",
    "docs = []\n",
    "\n",
    "#note: not using pretrained model because it adds predictions, just want LitBank data\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe('sentencizer') # used in training assessment\n",
    "\n",
    "\n",
    "for text_file in tqdm(text_files):\n",
    "    doc = nlp(text_file.read_text())\n",
    "    annotation_file = (entities_path / (text_file.stem +'.ann'))\n",
    "    annotations = annotation_file.read_text().split('\\n')\n",
    "    ents = []\n",
    "    for annotation in annotations[:-1]:\n",
    "        label, start, end = annotation.split('\\t')[1].split()\n",
    "        span = doc.char_span(int(start), int(end), label=label)\n",
    "        if span: # when start and end do not match a valid string, spaCy returns a NoneType span\n",
    "            ents.append(span)\n",
    "    \n",
    "    filtered = filter_spans(ents)\n",
    "    doc.ents = filtered\n",
    "    docs.append(doc)\n",
    "    \n",
    "\n",
    "assert len(docs) == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e60eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 90 training docs\n",
      "Created 10 validation docs\n"
     ]
    }
   ],
   "source": [
    "# Split the data into sets for training and validation \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, validation_set = train_test_split(docs, test_size=0.1)\n",
    "print(f'Created {len(train_set)} training docs')\n",
    "print(f'Created {len(validation_set)} validation docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4afb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training Docs to DocBin and store to disk\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "# the DocBin will store the training documents\n",
    "train_db = DocBin()\n",
    "for doc in train_set:\n",
    "    train_db.add(doc)\n",
    "train_db.to_disk(\"./train.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1884af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the validation Docs to disk \n",
    "validation_db = DocBin()\n",
    "for doc in validation_set:\n",
    "    validation_db.add(doc)\n",
    "    \n",
    "validation_db.to_disk(\"./dev.spacy\") # the spaCy doc refer to development data rather than validation, change our language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc36b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root  166113 Dec 16 19:36 dev.spacy\r\n",
      "-rw-r--r-- 1 root root 1406011 Dec 16 19:36 train.spacy\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al train.spacy dev.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a96434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy init config ./config.cfg --lang en --pipeline ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef03ecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: cpu_config.cfg: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# inspect the new config.cfg file \n",
    "!cat cpu_config.cfg\n",
    "# or %load config.cfg (but cell becomes very long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb6d34ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 31.5 µs\n",
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-12-16 20:12:56,934] [INFO] Set up nlp object from config\n",
      "[2021-12-16 20:12:56,957] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-12-16 20:12:56,959] [INFO] Created vocabulary\n",
      "[2021-12-16 20:12:56,960] [INFO] Finished initializing nlp object\n",
      "[2021-12-16 20:13:02,502] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00   1138.38    0.00    0.00    0.00    0.00\n",
      "^C\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "!python3 -m spacy train config.cfg --output ./output --paths.train train.spacy --paths.dev dev.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbd894df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I The Old Pyncheon Family HALFWAY down a by-street of one of our New England towns stands a rusty wooden house , with seven acutely peaked gables , facing towards various points of the compass , and a huge , clustered chimney in the midst .</br>The street is Pyncheon Street ; the house is the old Pyncheon House ; and an elm-tree , of wide circumference , rooted before the door , is familiar to every town-born child by the title of the Pyncheon Elm .</br>On my occasional visits to </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the predictions of our new model\n",
    "import random\n",
    "from spacy import displacy \n",
    "\n",
    "new_nlp = spacy.load(\"output/model-last\")\n",
    "val_doc = random.choice(validation_set)\n",
    "doc = new_nlp(val_doc.text)\n",
    "\n",
    "displacy.render(doc[:100], jupyter=True, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01af332a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Old Pyncheon Family\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " HALFWAY down \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    a by-street of one of our New England towns\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " stands \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    a rusty wooden house , with seven acutely peaked gables , facing towards various points of the compass\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " , and a huge , clustered chimney in the midst .</br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The street\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " is \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pyncheon Street\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " ; \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the house\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " is \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the old Pyncheon House\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " ; and an elm-tree , of wide circumference , rooted before the door , is familiar to \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    every town-born child\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " by the title of the Pyncheon Elm .</br>On my occasional visits to </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare against the original LitBank annotations \n",
    "displacy.render(val_doc[:100], jupyter=True, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2d16ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://spacy.io/api/language#evaluate\n",
    "from spacy.training import Example\n",
    "\n",
    "examples =[]\n",
    "for val_doc in train_set + validation_set:\n",
    "    new_doc = new_nlp(val_doc.text)\n",
    "    examples.append(Example(new_doc, val_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c6fcca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'sents_p': 1.0, 'sents_r': 1.0, 'sents_f': 1.0, 'speed': 121138.01940589753}\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "scores = nlp.evaluate(examples)\n",
    "print(scores)\n",
    "print(len(examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d450980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
